[net]
# Testing
batch=1
subdivisions=1
width=736
height=736
#
# Training
# batch=64
# subdivisions=4
# width=416
# height=416

channels=1
momentum=0.9
decay=0.0005

# angle=45
# # saturation = 1.5
# exposure = 1.5
# # hue=.1

angle=30
# saturation = 1.5
exposure = 1.3
# hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 7000
policy=steps

# steps=100,4800,5400
# scales=10,.1,.1
steps=2000,3000,4000
scales=.1,.1,.1

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=1

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

###########

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
# filters=425
filters=30
activation=linear

[region]
# classes=80
classes=1
# anchors =  0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828
# num=5
anchors = 0.5750,0.7667,   0.5750,0.7667,   0.5750,0.7667,   0.5750,0.7667,   0.5750,0.7667
num=5
bias_match=1
coords=4
softmax=1
jitter=.2
rescore=0

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=1
thresh = .6
random=1
